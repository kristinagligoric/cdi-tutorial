{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30319be7-e7f0-4ca1-aaa3-be73ad78e921",
   "metadata": {},
   "source": [
    "### This is a non-adaptive version of the tutorial, where we collect all the human annotations in a single batch\n",
    "- Texts are randomly selected for human annotations, according to the budget\n",
    "- We then leverage the verbalized confidence scores and limited human annotations for valid statistical inference\n",
    "- We assume human annotations, llm annotations, and llm confidence have already been collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89875d1-3076-44bb-b7a2-200fa497520e",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782ce87f-8c5b-4e0b-a1bb-d592f3312eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from ppi_py.utils import bootstrap\n",
    "import re\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from utils import inference\n",
    "from utils.inference import confidence_driven_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c5c3f-f304-440b-a137-96b67757a36f",
   "metadata": {},
   "source": [
    "### Set your file parameters and needed columns\n",
    "\n",
    "1. The file path\n",
    "2. Human labels (textual labels such as \"positive\" or \"negative\", or \"polite\" or \"impolite\")\n",
    "3. LLM labels (textual labels such as \"positive\" or \"negative\", or \"polite\" or \"impolite\")\n",
    "4. A text-based feature (0 or 1 indicating presence or absence of a textual feature)\n",
    "5. What class will be considered as positive (the class we are focusing on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078dcc95-7104-4617-9661-15b319b10270",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace with your path and your column names\n",
    "\n",
    "# The file path\n",
    "dataset = 'data/politeness_dataset_human_incomplete.csv'\n",
    "\n",
    "# The name of the column with human labels\n",
    "human_labels = 'Prediction_human'\n",
    "\n",
    "# The name of the column with LLM labels\n",
    "llm_labels = 'Prediction_gpt-4o'\n",
    "\n",
    "# The name of the column with a text-based feature\n",
    "text_based_feature = 'Feature_3'\n",
    "\n",
    "# What class will be considered as positive (the class we are focusing on)\n",
    "positive_class = 'Polite'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3373c599-5e5e-4467-ba2f-ccb6ad81d38c",
   "metadata": {},
   "source": [
    "### Set parameters for Confidence-Driven Inference (CDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e02c1a9-0d11-47fe-b158-4e2509a7479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1  # desired error level for confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef9902-4cd6-45cd-b9e2-24e22cfa1a20",
   "metadata": {},
   "source": [
    "### Step 1: Load the texts and LLM annotations\n",
    "\n",
    "#### We will showcase the estimation of two target statistics:\n",
    "1. $\\mathrm{mean}(H)$, i.e., the fraction of texts in the corpus that are labeled as the positive class\n",
    "2. The impact of text-based feature ($X$), on the positive class annotation ($H$), estimated with a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cfc30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(pd.read_csv(dataset))\n",
    "data = pd.DataFrame()\n",
    "\n",
    "#load the text-based feature\n",
    "data['X'] = pd.read_csv(dataset)[text_based_feature].values\n",
    "\n",
    "#load the extisting LLM annotations we already collected\n",
    "data['llm'] = pd.read_csv(dataset)[llm_labels].apply(lambda x: 1 if x.lower()==positive_class.lower() else 0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d13cb2-b36e-452e-bad1-54e68038c54e",
   "metadata": {},
   "source": [
    "### Step 2: Load human annotations (in a single batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08063281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 human datapoints collected in total.\n"
     ]
    }
   ],
   "source": [
    "#load the extisting human annotations we already collected\n",
    "data['human'] = pd.read_csv(dataset)[[human_labels]].values\n",
    "\n",
    "n_human = sum(~data['human'].isna())\n",
    "print(f\"{len(data.dropna(subset = ['human']))} human datapoints collected in total.\")\n",
    "\n",
    "data['sampling_decisions'] = (~data['human'].isna()).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cac03860-80e5-41ea-9820-4a5a508d6683",
   "metadata": {},
   "source": [
    "### Step 3: Compute the estimate and confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05da928d-6afa-4ab8-a875-306c75ed068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the estimator function\n",
    "#mask for valid labels and specify how to use weights\n",
    "\n",
    "def mean_estimator(y, weights):\n",
    "    y, weights = y[~np.isnan(y)], weights[~np.isnan(y)]\n",
    "    return np.sum(y * weights) / np.sum(weights)\n",
    "\n",
    "def log_reg_estimator(X, y, weights):\n",
    "    X, y, weights = X[~np.isnan(y)], y[~np.isnan(y)], weights[~np.isnan(y)]\n",
    "    return LogisticRegression(solver=\"liblinear\").fit(X, y, sample_weight=weights).coef_[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935732a-18af-42ff-848c-3929595fe0ef",
   "metadata": {},
   "source": [
    "#### $\\mathrm{mean}(H)$ estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4049879-79e5-44b2-a85e-38c7c1be3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDI estimate of the target statistic (mean(H)):\n",
      "point estimate: 0.5133\n",
      "confidence intervals: 0.4954 0.5303\n"
     ]
    }
   ],
   "source": [
    "estimate, (lower_bound, upper_bound) = confidence_driven_inference(\n",
    "    estimator = mean_estimator,\n",
    "    Y = data['human'].values,\n",
    "    Yhat = data['llm'].values,\n",
    "    sampling_probs =  np.ones(len(data))/len(data),\n",
    "    sampling_decisions = data['sampling_decisions'].values,\n",
    "    alpha = alpha)\n",
    "\n",
    "print(\"CDI estimate of the target statistic (mean(H)):\")\n",
    "print('point estimate:',estimate.round(4))\n",
    "print('confidence intervals:', lower_bound.round(4), upper_bound.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10395a03-bb95-4a1f-9c7c-760459c0a007",
   "metadata": {},
   "source": [
    "#### $\\beta$ estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba13bbd2-e85e-4321-bd65-1be9d7a016fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDI estimate of the target statistic (β: effect of X on H):\n",
      "point estimate: 0.4433\n",
      "confidence intervals: 0.2734 0.5991\n"
     ]
    }
   ],
   "source": [
    "estimate, (lower_bound, upper_bound) = confidence_driven_inference(\n",
    "    estimator = log_reg_estimator,\n",
    "    Y = data['human'].values,\n",
    "    Yhat = data['llm'].values,\n",
    "    X = data['X'].values.reshape(-1, 1),\n",
    "    sampling_probs =  np.ones(len(data))/len(data),\n",
    "    sampling_decisions = data['sampling_decisions'].values,\n",
    "    alpha = alpha)\n",
    "\n",
    "print(\"CDI estimate of the target statistic (β: effect of X on H):\")\n",
    "print('point estimate:',estimate.round(4))\n",
    "print('confidence intervals:', lower_bound.round(4), upper_bound.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
